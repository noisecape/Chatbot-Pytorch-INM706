{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from dataset import CornellCorpus\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model import Encoder, Decoder, ChatbotModel, EncoderAttention, LuongAttentionDecoder, Attention, GreedySearch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# check cuda availability\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(device)\n",
    "\n",
    "# define the dir where to save the trained model\n",
    "save_model_dir = 'saved_models'\n",
    "if not os.path.exists(save_model_dir):\n",
    "    os.mkdir(save_model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# define some useful functions\n",
    "\n",
    "def get_movie_lines(path):\n",
    "    \"\"\"\n",
    "    This function extracts the movie lines id and the text associated\n",
    "    and store them in a dictionary.\n",
    "    :param path: the path where to find the file 'movie_lines.txt'\n",
    "    :return line_to_phrase: the dictionary that maps each line id to the corresponding text\n",
    "    \"\"\"\n",
    "    file = open(path, 'r', encoding='iso-8859-1')\n",
    "    dialog_data = []\n",
    "    line_to_phrase = {}\n",
    "    for line in file.readlines():\n",
    "        dialog_data.append(line.strip().split(sep=' +++$+++ '))\n",
    "    for information in dialog_data:\n",
    "        line_to_phrase[information[0]] = information[-1].replace('\\n', '')\n",
    "    return line_to_phrase\n",
    "\n",
    "\n",
    "def extract_dialogs():\n",
    "    \"\"\"\n",
    "    This function extracts dialogs from each movie. A dialog is represented by\n",
    "    a list on lineid which identifies a unique conversation in the dataset.\n",
    "    :return conversation:\n",
    "    \"\"\"\n",
    "    PATH_CONVERSATION = os.path.join(os.curdir, 'cornell-movie-dialogs-corpus/movie_conversations.txt')\n",
    "    file = open(PATH_CONVERSATION, 'r', encoding='iso-8859-1')\n",
    "    dialog_list = []\n",
    "\n",
    "    # extract conversations info from 'movie_conversation.txt'\n",
    "    for line in file.readlines():\n",
    "        line = line.split(' +++$+++ ')\n",
    "        regex = re.compile('[^a-zA-Z0-9.,!?]')\n",
    "        line = regex.sub('', line[-1])\n",
    "        line = line.split(',')\n",
    "        dialog_list.append(line)\n",
    "\n",
    "    return dialog_list\n",
    "\n",
    "\n",
    "def create_pair_dialogs(dialogs):\n",
    "    # dictionary that stores the following [question] -> [answer] for each line in a dialog\n",
    "    dialogs_pairs = []\n",
    "    for dialog in dialogs:\n",
    "        for idx in range(len(dialog) - 1):\n",
    "            question_to_answer = []\n",
    "            question_to_answer.append(dialog[idx])\n",
    "            question_to_answer.append(dialog[idx+1])\n",
    "            # check if either the answer or the question is empty and if that's the case don't append it.\n",
    "            if dialog[idx] and dialog[idx+1]:\n",
    "                dialogs_pairs.append(question_to_answer)\n",
    "    return dialogs_pairs\n",
    "\n",
    "\n",
    "def format_time(start, end):\n",
    "    elapsed_time = end - start\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_secs, elapsed_mins\n",
    "\n",
    "def pad_sequence(sequence, max_length):\n",
    "    pad_token_idx = vocabulary.word_to_idx['<PAD>']\n",
    "    while len(sequence) <= max_length:\n",
    "        sequence.append(pad_token_idx)\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def format_user_input(sequence, max_length=10):\n",
    "    # convert each word into index from the vocabulary\n",
    "    regex = re.compile('[^a-zA-Z0-9.!?]')\n",
    "    sequence = regex.sub(' ', sequence)\n",
    "    # remove extra space\n",
    "    sequence = re.sub(r\"([.!?'])\", r\" \\1\", sequence)\n",
    "    # remove non-letter characters but keep regular punctuation\n",
    "    sentence = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", sequence)\n",
    "    sequence = sequence.lower()\n",
    "    sequence = sequence.strip().split()\n",
    "    user_seq_indices = []\n",
    "    for word in sequence:\n",
    "        if word in vocabulary.word_to_idx.keys():\n",
    "            user_seq_indices.append(vocabulary.word_to_idx[word])\n",
    "        else:\n",
    "            user_seq_indices.append(vocabulary.word_to_idx['<UNK>'])\n",
    "\n",
    "    # pad or trim the sentence\n",
    "    if len(user_seq_indices) > max_length:  # trim\n",
    "        user_seq_indices = user_seq_indices[:max_length]\n",
    "        user_seq_indices.append(vocabulary.word_to_idx['</S>'])\n",
    "    elif len(user_seq_indices) <= max_length:  # pad\n",
    "        user_seq_indices.append(vocabulary.word_to_idx['</S>'])\n",
    "        user_seq_indices = pad_sequence(user_seq_indices, max_length)\n",
    "    user_seq_indices = torch.tensor(user_seq_indices).unsqueeze(1)\n",
    "    user_seq_indices = user_seq_indices.to(device)\n",
    "    return user_seq_indices\n",
    "\n",
    "\n",
    "def convert_to_string(reply):\n",
    "    parsed_reply = []\n",
    "    for word_idx in reply:\n",
    "        # if the word is PAD or END of Sentence token, ignore it.\n",
    "        word_idx = word_idx.cpu().numpy()[0][0]\n",
    "        reply = vocabulary.vocab[word_idx]\n",
    "        if word_idx == vocabulary.word_to_idx['<PAD>'] or word_idx == vocabulary.word_to_idx['</S>']:\n",
    "            break\n",
    "        else:\n",
    "            parsed_reply.append(reply)\n",
    "\n",
    "    return ' '.join(parsed_reply)\n",
    "\n",
    "\n",
    "def map_to_idx(sequence):\n",
    "    seq_idx = []\n",
    "    for word in sequence:\n",
    "        seq_idx.append(vocabulary.word_to_idx[word])\n",
    "    return seq_idx\n",
    "\n",
    "\n",
    "# evaluate the model to talk with it.\n",
    "def evaluate(seq, searcher):\n",
    "    # tensor should have shape [seq, 1]\n",
    "    seq = seq.to(device)\n",
    "    # feedforward to the searcher to get the list of most likely indices of words\n",
    "    bot_reply = searcher(seq)\n",
    "    # discard first element which is the start token\n",
    "    bot_reply = bot_reply[1:].to(device)\n",
    "    bot_reply = torch.topk(bot_reply, 1)\n",
    "    bot_reply = bot_reply.indices\n",
    "    # convert indices to words.\n",
    "    bot_reply = convert_to_string(bot_reply)\n",
    "    return bot_reply\n",
    "\n",
    "\n",
    "def init_model(with_attention=False):\n",
    "    if with_attention:\n",
    "        # init with attention\n",
    "        encoder = EncoderAttention(embedding_size, hidden_size, vocabulary.__len__()).to(device)\n",
    "        attention = Attention(hidden_size).to(device)\n",
    "        decoder = LuongAttentionDecoder(embedding_size, hidden_size, vocabulary.__len__(), attention=attention).to(\n",
    "            device)\n",
    "        model = ChatbotModel(encoder, decoder, vocabulary.__len__(), with_attention=True).to(device)\n",
    "        return encoder, decoder, model\n",
    "    else:\n",
    "        # init with no attention\n",
    "        encoder = Encoder(embedding_size, hidden_size, vocabulary.__len__()).to(device)\n",
    "        decoder = Decoder(embedding_size, hidden_size, vocabulary.__len__()).to(device)\n",
    "        model = ChatbotModel(encoder, decoder, vocabulary.__len__(), with_attention=False).to(device)\n",
    "        return encoder, decoder, model\n",
    "\n",
    "\n",
    "def run_bot(searcher, testing=True, max_length=10):\n",
    "    model.encoder.eval()\n",
    "    model.decoder.eval()\n",
    "    if testing:\n",
    "        user_input = 'Hey how are you?'\n",
    "        user_input_idx = format_user_input(user_input, max_length)\n",
    "        reply = evaluate(user_input_idx, searcher)\n",
    "        print(reply)\n",
    "    else:\n",
    "        while(True):\n",
    "            try:\n",
    "                # ask the user for the input\n",
    "                user_input = input('> ')\n",
    "                # format the user input.\n",
    "                if user_input == 'quit':\n",
    "                    break\n",
    "                user_input_idx = format_user_input(user_input, max_length)\n",
    "                # run the evaluate function to get bot's reply\n",
    "                reply = evaluate(user_input_idx, searcher)\n",
    "                print(reply)\n",
    "            except KeyError:\n",
    "                print('Error: While parsing the input sentence...')\n",
    "\n",
    "def compute_bleu_score():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Define the Vocabulary class\n",
    "\n",
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, idx_to_text, dialogs_ids):\n",
    "        self.dialogs_ids = dialogs_ids\n",
    "        self.idx_to_text = self.normalize_sentence(idx_to_text)\n",
    "        self.word_to_idx = self.map_word_to_idx()\n",
    "        self.vocab = self.map_idx_to_word()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def normalize_sentence(self, idx_to_text):\n",
    "        normalized_idx_to_sentence = {}\n",
    "        for line_id, sentence in zip(idx_to_text.keys(), idx_to_text.values()):\n",
    "            # convert each word in the sentence to a lower case\n",
    "            sentence = sentence.lower()\n",
    "            # eliminate extra spaces for punctuation\n",
    "            sentence = re.sub(r\"([.,!?'])\", r\" \\1\", sentence)\n",
    "            # remove non-letter characters but keep regular punctuation\n",
    "            sentence = re.sub(r\"[^a-zA-Z,.?!]+\", r\" \", sentence)\n",
    "            normalized_idx_to_sentence[line_id] = sentence\n",
    "\n",
    "        # filters empty q-a pairs\n",
    "        filtered_sentences = {}\n",
    "        for line_id, text in zip(normalized_idx_to_sentence.keys(), normalized_idx_to_sentence.values()):\n",
    "            if text != ' ':\n",
    "                filtered_sentences[line_id] = text\n",
    "            else:\n",
    "                print('empty')\n",
    "        print('Filtered sentences: {}'.format(len(normalized_idx_to_sentence) - len(filtered_sentences)))\n",
    "        return normalized_idx_to_sentence\n",
    "\n",
    "    def map_idx_to_word(self):\n",
    "        words = self.word_to_idx.keys()\n",
    "        index = self.word_to_idx.values()\n",
    "        idx_to_word = OrderedDict()\n",
    "        for w, i in zip(words, index):\n",
    "            idx_to_word[i] = w\n",
    "        return idx_to_word\n",
    "\n",
    "    def map_word_to_idx(self):\n",
    "        word_to_idx = {}\n",
    "        count_words = 0\n",
    "        for dialogs in self.dialogs_ids:\n",
    "            for line in dialogs:\n",
    "                sentence = self.idx_to_text[line]\n",
    "                for word in sentence.strip().split():\n",
    "                    if word not in word_to_idx:\n",
    "                        word_to_idx[word] = count_words\n",
    "                        count_words += 1\n",
    "        start_token = '<S>'\n",
    "        end_token = '</S>'\n",
    "        unknown_token = '<UNK>'\n",
    "        pad_token = '<PAD>'\n",
    "        word_to_idx = sorted(word_to_idx)\n",
    "        word_to_idx.insert(0, unknown_token)\n",
    "        word_to_idx.insert(0, end_token)\n",
    "        word_to_idx.insert(0, start_token)\n",
    "        word_to_idx.insert(0, pad_token)\n",
    "        word_to_idx = self.build_dictionary(word_to_idx)\n",
    "        return word_to_idx\n",
    "\n",
    "    def build_dictionary(self, word_collection):\n",
    "        word_to_idx = OrderedDict()\n",
    "        for idx, word in enumerate(word_collection):\n",
    "            word_to_idx[word] = idx\n",
    "        return word_to_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n",
      "empty\n",
      "Filtered sentences: 2\n",
      "Total words counted in the vocabulary: 49607\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "Total training batches: 177290, Total val batches: 22161, Total test batches: 22162\n"
     ]
    }
   ],
   "source": [
    "dirs = os.path.join(os.curdir, 'cornell-movie-dialogs-corpus/movie_lines.txt')\n",
    "idx_to_text = get_movie_lines(dirs)\n",
    "# create a list of dialogs for each movie.\n",
    "dialogs = extract_dialogs()\n",
    "# for each movie, create pairs dialogs (Q/A). This is the actual data used for training.\n",
    "pair_dialogs_idx = create_pair_dialogs(dialogs)\n",
    "# instantiate the vocabulary\n",
    "vocabulary = Vocabulary(idx_to_text, dialogs)\n",
    "print('Total words counted in the vocabulary: {}'.format(vocabulary.__len__()))\n",
    "\n",
    "# shuffle data\n",
    "np.random.shuffle(pair_dialogs_idx)\n",
    "train_data = CornellCorpus(pair_dialogs_idx, vocabulary, max_length=10, stage='train')\n",
    "val_data = CornellCorpus(pair_dialogs_idx, vocabulary, max_length=10, stage='val')\n",
    "test_data = CornellCorpus(pair_dialogs_idx, vocabulary, max_length=10, stage='test')\n",
    "\n",
    "print('Total training batches: {}, Total val batches: {}, Total test batches: {}'.format(train_data.__len__(),\n",
    "                                                                                         val_data.__len__(),\n",
    "                                                                                         test_data.__len__()))\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64\n",
    "hidden_size = 256\n",
    "embedding_size = 300\n",
    "epochs = 10\n",
    "\n",
    "# init dataloader\n",
    "load_args = {'batch_size': batch_size, 'shuffle': True}\n",
    "train_dataloader = DataLoader(train_data, **load_args)\n",
    "val_dataloader = DataLoader(val_data, **load_args)\n",
    "test_dataloader = DataLoader(test_data, **load_args)\n",
    "\n",
    "# init model\n",
    "encoder, decoder, model = init_model(with_attention=True)\n",
    "\n",
    "# init loss function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocabulary.word_to_idx['<PAD>'])\n",
    "epoch_history = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    batch_history = []\n",
    "    model.encoder.train()\n",
    "    model.decoder.train()\n",
    "    avg_loss = 0\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "    for idx, X in enumerate(train_dataloader):\n",
    "        # transpose both input sentence and target sentence to access using the first dimension\n",
    "        # the the i-th word for each batch at each given time step t.\n",
    "        question = torch.transpose(X[0].to(device), 0, 1)\n",
    "        answer = torch.transpose(X[1].to(device), 0, 1)\n",
    "        # compute the output. Recall the output size should be (seq_len, batch_size, voc_size)\n",
    "        output = model(question, answer)\n",
    "\n",
    "        # don't consider the first element in all batches because it's the '<S>' token\n",
    "        output = output[1:].to(device)\n",
    "        answer = answer[1:].to(device)\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        answer = answer.reshape(-1)\n",
    "\n",
    "        loss = criterion(output, answer)\n",
    "        # default previous weights values\n",
    "        model.encoder.optim.zero_grad()\n",
    "        model.decoder.optim.zero_grad()\n",
    "        # backpropagate to compute gradients\n",
    "        loss.backward()\n",
    "        # clip gradients to avoid exploding values\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=50)\n",
    "        model.encoder.optim.step()\n",
    "        model.decoder.optim.step()\n",
    "        batch_history.append(loss.item())\n",
    "        # print current loss every 500 processed batches\n",
    "        if idx % 500 == 0:\n",
    "            # end of epoch\n",
    "            end_time = time.time()\n",
    "            # format elapsed time\n",
    "            elapsed_secs, elapsed_mins = format_time(start_time, end_time)\n",
    "            print('BATCH [{}/{}], LOSS TRAINING: {}, eta: {}m {}s'.format(idx,\n",
    "                                                                          train_dataloader.__len__(),\n",
    "                                                                          loss,\n",
    "                                                                          elapsed_mins,\n",
    "                                                                          elapsed_secs))\n",
    "            # start timer\n",
    "            start_time = time.time()\n",
    "    avg_loss = np.sum(batch_history) / train_dataloader.__len__()\n",
    "    return avg_loss\n",
    "\n",
    "def val_loop():\n",
    "    model.encoder.eval()\n",
    "    model.decoder.eval()\n",
    "    batch_history = []\n",
    "    avg_loss = 0\n",
    "    for idx, X in enumerate(val_dataloader):\n",
    "        # transpose both input sentence and target sentence to access using the first dimension\n",
    "        # the the i-th word for each batch at each given time step t.\n",
    "        question = torch.transpose(X[0].to(device), 0, 1)\n",
    "        answer = torch.transpose(X[1].to(device), 0, 1)\n",
    "        # compute the output. Recall the output size should be (seq_len, batch_size, voc_size)\n",
    "        output = model(question, answer)\n",
    "        # don't consider the first element in all batches because it's the '<S>' token\n",
    "        output = output[1:].to(device)\n",
    "        answer = answer[1:].to(device)\n",
    "        # reshape both question and answer to the correct size for the loss function\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        answer = answer.reshape(-1)\n",
    "        # compute the loss\n",
    "        loss = criterion(output, answer)\n",
    "\n",
    "        # keep track of the loss\n",
    "        batch_history.append(loss.item())\n",
    "    avg_loss = np.sum(batch_history) / val_dataloader.__len__()\n",
    "    # test learning with dummy phrase\n",
    "    print(\"Test learning, input phrase: 'Hey what's your name?'\")\n",
    "    if model.attention:\n",
    "        searcher = GreedySearch(encoder, decoder, vocabulary, attention=True).to(device)\n",
    "    else:\n",
    "        searcher = GreedySearch(encoder, decoder, vocabulary, attention=False).to(device)\n",
    "    run_bot(searcher)\n",
    "    return avg_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "BATCH [0/2771], LOSS TRAINING: 10.818685531616211, eta: 0m 6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-5842c5897c04>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0mstart_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0;31m# compute train loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m         \u001B[0mtrain_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_loop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m         \u001B[0;31m# compute val loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0mval_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mval_loop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-ce1f71becccb>\u001B[0m in \u001B[0;36mtrain_loop\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m         \u001B[0;31m# backpropagate to compute gradients\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m         \u001B[0;31m# clip gradients to avoid exploding values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclip_grad_norm_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    219\u001B[0m                 \u001B[0mretain_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m                 create_graph=create_graph)\n\u001B[0;32m--> 221\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[1;32m    128\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 130\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    131\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "### TRAIN LOOP ###\n",
    "\n",
    "epoch_idx = 0\n",
    "\n",
    "if model.attention:\n",
    "    checkpoint_path = os.path.join(os.curdir, 'saved_models/checkpoint.pth')\n",
    "    path_saved_model = os.path.join(os.curdir, 'saved_models/trained_model.pth')\n",
    "else:\n",
    "    checkpoint_path = os.path.join(os.curdir, 'saved_models/checkpoint_no_att.pth')\n",
    "    path_saved_model = os.path.join(os.curdir, 'saved_models/trained_model_no_att.pth')\n",
    "    # check if the model is already trained\n",
    "if os.path.exists(path_saved_model):\n",
    "    # load state_dict\n",
    "    print('Trained model found. Loading...')\n",
    "    model.load_state_dict(torch.load(path_saved_model, map_location=torch.device(device)))\n",
    "    print('Model loaded.')\n",
    "else:\n",
    "    # check if a training phase was already started\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        # load trained values\n",
    "        loaded_checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "        print('Checkpoint found. Restore from [{}/{}] epoch.'.format(loaded_checkpoint['epoch'], epochs))\n",
    "        # restore previous values\n",
    "        epoch_idx = loaded_checkpoint['epoch']\n",
    "        model.load_state_dict(loaded_checkpoint['model_sd'])\n",
    "        model.optim.load_state_dict(loaded_checkpoint['optim_sd'])\n",
    "\n",
    "    # UNCOMMENT THE BELOW TO CONTINUE TRAINING\n",
    "\n",
    "    print('Start training...')\n",
    "    for epoch in range(epoch_idx, epochs):\n",
    "        # start counting epoch time\n",
    "        start_time = time.time()\n",
    "        # compute train loss\n",
    "        train_loss = train_loop()\n",
    "        # compute val loss\n",
    "        val_loss = val_loop()\n",
    "        # store train and val loss for later analysis\n",
    "        epoch_history.append((train_loss, val_loss))\n",
    "        # end of epoch\n",
    "        end_time = time.time()\n",
    "        # format elapsed time\n",
    "        elapsed_secs, elapsed_mins = format_time(start_time, end_time)\n",
    "        checkpoint = {'epoch': epoch,\n",
    "                      'optim_sd': model.optim.state_dict(),\n",
    "                      'model_sd': model.state_dict(),\n",
    "                      'train_loss': train_loss,\n",
    "                      'val_loss': val_loss\n",
    "                      }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(\"EPOCH [{}/{}] | Train Loss: {} | Val. Loss: {} | time: {}m {}s\".format(epoch+1,\n",
    "                                                                                           epochs,\n",
    "                                                                                           train_loss,\n",
    "                                                                                           val_loss,\n",
    "                                                                                           elapsed_mins,\n",
    "                                                                                           elapsed_secs))\n",
    "    # save training model.\n",
    "    print('Training completed.')\n",
    "    torch.save(model.state_dict(), path_saved_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluating the Chatbot\n",
    "searcher = GreedySearch(encoder, decoder, vocabulary, attention=True)\n",
    "run_bot(searcher, testing=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}